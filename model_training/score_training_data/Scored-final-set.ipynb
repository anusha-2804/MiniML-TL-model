{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ef0900-975f-4d82-9d84-7a56445dee46",
   "metadata": {},
   "source": [
    "To combined scored dataset from all cells, then to inspect this final combined scored dataset and to save the dataset with removing all stretches that have been marked as '2'/'unclear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab92a6-7b79-482b-8844-3f94648945c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to combine the scored dataset from all cell - added by Anusha\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "def combine_datasets(file_list, output_file):\n",
    "    combined_events = []\n",
    "    combined_scores = []\n",
    "\n",
    "    for file in file_list:\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            combined_events.append(f['events'][:])\n",
    "            combined_scores.append(f['scores'][:])\n",
    "\n",
    "    combined_events = np.concatenate(combined_events, axis=0)\n",
    "    combined_scores = np.concatenate(combined_scores, axis=0)\n",
    "\n",
    "    with h5py.File(output_file, 'w') as f:\n",
    "        f.create_dataset(\"events\", data=combined_events)\n",
    "        f.create_dataset(\"scores\", data=combined_scores)\n",
    "\n",
    "    print(f'Combined data saved to {output_file}')\n",
    "\n",
    "# File paths of the individual datasets\n",
    "file_list = [\n",
    "    'C:/Users/Anusha/Documents/GitHub/miniML/model_training/scored-cell1-S6-4-740w.h5',\n",
    "    'C:/Users/Anusha/Documents/GitHub/miniML/model_training/cell1-S4-27-750w.h5',\n",
    "    'C:/Users/Anusha/Documents/GitHub/miniML/model_training/scored-cell2-750w.h5',\n",
    "    'C:/Users/Anusha/Documents/GitHub/miniML/model_training/scored-cell4-750w.h5',\n",
    "    'C:/Users/Anusha/Documents/GitHub/miniML/model_training/scored-cell6-750w.h5',\n",
    "    'C:/Users/Anusha/Documents/GitHub/miniML/model_training/scored-cell5-750w.h5',\n",
    "    'C:/Users/Anusha/Documents/GitHub/miniML/model_training/scored-cell5-1-750w.h5'\n",
    "    \n",
    "]\n",
    "\n",
    "# Output file path for the combined dataset\n",
    "output_file = 'C:/Users/Anusha/Documents/GitHub/miniML/model_training/combined_FINAL.h5'\n",
    "\n",
    "# Combine the datasets\n",
    "combine_datasets(file_list, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced0544a-aef5-4fc7-9a00-d4ea0033b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from ScoringPanel2 import ScoringPanel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f429dde-555c-4194-9e16-06dffcbae397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2456, 750) (2456,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('C:/Users/Anusha/Documents/GitHub/miniML/model_training/score_training_data/Model 5 scored/FINALSET.h5', 'r') as f:\n",
    "    x = f['events'][:]\n",
    "    y = f['scores'][:]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd1f011-49eb-4ee2-873e-e907445e4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Open plot for scoring\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "tracker = ScoringPanel2(fig, ax, x, y, start_ind=0)\n",
    "fig.canvas.mpl_connect('key_press_event', tracker.onclick)\n",
    "fig.canvas.mpl_connect('scroll_event', tracker.onscroll)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b129632f-0c24-4840-9588-3711799bd379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of labels:\n",
      "Label 0: 600 events\n",
      "Label 1: 600 events\n",
      "Label 2: 1256 events\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the summary of labels to keep a track of how many datastretches are in each category\n",
    "label_counts = {\n",
    "    0: np.sum(y == 0),\n",
    "    1: np.sum(y == 1),\n",
    "    2: np.sum(y == 2)\n",
    "}\n",
    "\n",
    "print(f\"Summary of labels:\")\n",
    "print(f\"Label 0: {label_counts[0]} events\")\n",
    "print(f\"Label 1: {label_counts[1]} events\")\n",
    "print(f\"Label 2: {label_counts[2]} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d16bc807-e8a3-4a89-99bb-166ee4bc95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_indices = y != 2\n",
    "x_filtered = x[filtered_indices]\n",
    "y_filtered = y[filtered_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d02ce78-97f0-48f2-919b-0de8ebc77863",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset = 'C:/Users/Anusha/Documents/GitHub/miniML/model_training/score_training_data/Model 5 scored/FINALSET.h5'\n",
    "if save_dataset:\n",
    "    with h5py.File(save_dataset, 'w') as f:\n",
    "        f.create_dataset(\"events\", data=x_filtered)\n",
    "        f.create_dataset(\"scores\", data=y_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4189fb0a-1ce7-4c6f-879b-d449657f897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 750) (1200,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('C:/Users/Anusha/Documents/GitHub/miniML/model_training/score_training_data/Model 5 scored/FINALSET.h5', 'r') as f:\n",
    "    x = f['events'][:]\n",
    "    y = f['scores'][:]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81da55c8-4972-47d1-8908-28fa812fbf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Open plot for scoring\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "tracker = ScoringPanel2(fig, ax, x, y, start_ind=0)\n",
    "fig.canvas.mpl_connect('key_press_event', tracker.onclick)\n",
    "fig.canvas.mpl_connect('scroll_event', tracker.onscroll)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb933543-1f2a-46f6-8e9a-dcbfb6ebeb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of labels:\n",
      "Label 0: 600 events\n",
      "Label 1: 600 events\n",
      "Label 2: 0 events\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the summary of labels\n",
    "label_counts = {\n",
    "    0: np.sum(y == 0),\n",
    "    1: np.sum(y == 1),\n",
    "    2: np.sum(y == 2)\n",
    "}\n",
    "\n",
    "print(f\"Summary of labels:\")\n",
    "print(f\"Label 0: {label_counts[0]} events\")\n",
    "print(f\"Label 1: {label_counts[1]} events\")\n",
    "print(f\"Label 2: {label_counts[2]} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec22645-7fd9-47a2-91c8-a792e78cdcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
