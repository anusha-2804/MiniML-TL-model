{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52535d4-a9ce-40be-aa51-7b21b50d4daf",
   "metadata": {},
   "source": [
    "This is to score the extracted dataset from one cell. Multiple copies of this file is provided if user wants to score different cells simultaneously and then to edit the scores to maintain the ratio of events/noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b034a783-1709-4c51-9269-42c470d49b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from ScoringPanel import ScoringPanel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3170e0ed-928d-4a33-a8f0-aaa637bbf2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(348, 750) (348,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('C:/Users/Anusha/Documents/GitHub/miniML/model_training/extract_training_data/output/Model 5/030724_4_27', 'r') as f:\n",
    "    x = f['events'][:]\n",
    "    y = f['scores'][:]\n",
    "    cell_label = f['cell_label'][:]\n",
    "    timestamp = f['timestamp'][:]\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cfbbf8-6d3c-4eda-9659-b7afd04df151",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Open plot for scoring\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "tracker = ScoringPanel(fig, ax, x, y,cell_label, timestamp,start_ind=0)\n",
    "fig.canvas.mpl_connect('key_press_event', tracker.onclick)\n",
    "fig.canvas.mpl_connect('scroll_event', tracker.onscroll)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69391fe0-17e7-4962-b550-3d99cb058dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of labels:\n",
      "Label 0: 331 events\n",
      "Label 1: 161 events\n",
      "Label 2: 909 events\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the summary of labels for all scores\n",
    "label_counts = {\n",
    "    0: np.sum(y == 0),\n",
    "    1: np.sum(y == 1),\n",
    "    2: np.sum(y == 2)\n",
    "}\n",
    "\n",
    "print(f\"Summary of labels:\")\n",
    "print(f\"Label 0: {label_counts[0]} events\")\n",
    "print(f\"Label 1: {label_counts[1]} events\")\n",
    "print(f\"Label 2: {label_counts[2]} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efb5df02-0eb7-435f-8ed0-fd3a647467e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of quality labels (for scores 0 ):\n",
      "PN: 58 events\n",
      "FP: 14 events\n",
      "NE: 1 events\n",
      "BE: 0 events\n"
     ]
    }
   ],
   "source": [
    "# Calculate the summary of quality labels for score 0\n",
    "quality_label_counts = {\n",
    "    label: np.sum((tracker.event_labels == label) & (tracker.Y == 0))\n",
    "    for label in tracker.quality_labels\n",
    "}\n",
    "\n",
    "print(f\"\\nSummary of quality labels (for scores 0 ):\")\n",
    "for label, count in quality_label_counts.items():\n",
    "    print(f\"{label}: {count} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a9ea19d-8b25-4815-b236-b7658ace12ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of quality labels (for scores 1):\n",
      "PN: 0 events\n",
      "FP: 0 events\n",
      "NE: 81 events\n",
      "BE: 94 events\n"
     ]
    }
   ],
   "source": [
    "# Calculate the summary of quality labels for score 1\n",
    "quality_label_counts = {\n",
    "    label: np.sum((tracker.event_labels == label) & (tracker.Y == 1))\n",
    "    for label in tracker.quality_labels\n",
    "}\n",
    "\n",
    "print(f\"\\nSummary of quality labels (for scores 1):\")\n",
    "for label, count in quality_label_counts.items():\n",
    "    print(f\"{label}: {count} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f93624d8-d6d9-4986-a36a-8eb9a9bdbfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset = 'C:/Users/Anusha/Documents/GitHub/miniML/model_training/Model 2 scored/cell3.h5'\n",
    "if save_dataset:\n",
    "    with h5py.File(save_dataset, 'w') as f:\n",
    "        f.create_dataset(\"events\", data=x)\n",
    "        f.create_dataset(\"scores\", data=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a881d-9822-45a6-9a4c-f323f7505902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
